{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5764c29",
   "metadata": {},
   "source": [
    "# 篩選資料"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312f1d1b",
   "metadata": {},
   "source": [
    "## 留下圖(所有的標記檔長寬比>1.5 且標記文字中沒有*且含有中文字)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe728d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import json\n",
    "# import shutil\n",
    "# from PIL import Image, ImageDraw\n",
    "\n",
    "# def copy_images_with_conditions(annotation_file_path, source_folder, target_folder):\n",
    "#     with open(annotation_file_path, 'r', encoding='utf-8') as file:\n",
    "#         annotations = json.load(file)\n",
    "\n",
    "#     for image_key, annotation in annotations.items():\n",
    "#         image_filename = annotation[\"filename\"]\n",
    "#         image_path = os.path.join(source_folder, image_filename)\n",
    "\n",
    "#         regions = annotation[\"regions\"]\n",
    "\n",
    "#         # Check conditions for all regions\n",
    "#         all_regions_valid = all(is_valid_region(region) for region in regions)\n",
    "\n",
    "#         if all_regions_valid:\n",
    "#             # Create target folder if it doesn't exist\n",
    "#             os.makedirs(target_folder, exist_ok=True)\n",
    "\n",
    "#             # Copy the image to the target folder\n",
    "#             target_path = os.path.join(target_folder, image_filename)\n",
    "#             shutil.copy(image_path, target_path)\n",
    "\n",
    "# def is_valid_region(region):\n",
    "#     word = region[\"region_attributes\"].get(\"word\", \"\")\n",
    "#     if '*' not in word and any(c.isalpha() for c in word):\n",
    "#         # Calculate width and height of the bounding box\n",
    "#         x_coordinates = region[\"shape_attributes\"][\"all_points_x\"]\n",
    "#         y_coordinates = region[\"shape_attributes\"][\"all_points_y\"]\n",
    "#         width = max(x_coordinates) - min(x_coordinates)\n",
    "#         height = max(y_coordinates) - min(y_coordinates)\n",
    "\n",
    "#         # Check the width/height ratio condition\n",
    "#         ratio = width / height\n",
    "#         return ratio >= 1.5\n",
    "\n",
    "#     return False\n",
    "\n",
    "# # Replace these paths with your actual paths\n",
    "# annotation_file_path = r\"C:\\Users\\MAGIC\\Ching\\survey\\plan\\rawdata_all\\1Tainan\\1Tainan_ori_all.json\"\n",
    "# source_folder = r\"C:\\Users\\MAGIC\\Ching\\survey\\plan\\rawdata_all\\1Tainan\\images\"\n",
    "# target_folder = r\"C:\\Users\\MAGIC\\Ching\\survey\\plan\\rawdata_all\\1Tainan\\ocrRaw2\n",
    "# os.makedirs(target_folder, exist_ok=True)\n",
    "\n",
    "# copy_images_with_conditions(annotation_file_path, source_folder, target_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62a6dcb",
   "metadata": {},
   "source": [
    "## 真正洗出來的data 放在各個資料夾內\n",
    "先找出ROI ratio>1.5，再找出無*有中文字的部分(忽視直立路牌)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d09a43b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = ['1Tainan'] #, '2Penghu', '3Taoyuan']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6fcd63a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1Tainan的圖片和 CSV: C:\\Users\\MAGIC\\Ching\\survey\\plan\\rawdata_all\\1Tainan\\ocrRaw2\\output2.csv 已完成\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import shutil\n",
    "import csv\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "def copy_images_with_conditions(annotation_file_path, source_folder, target_folder, csv_file_path):\n",
    "    with open(annotation_file_path, 'r', encoding='utf-8') as file:\n",
    "        annotations = json.load(file)\n",
    "\n",
    "    # 開啟 CSV 檔案，準備寫入\n",
    "    with open(csv_file_path, 'w', newline='', encoding='big5') as csvfile:\n",
    "        fieldnames = ['raw_filename', 'ROI_count', 'category', 'box', 'words']\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "\n",
    "        # 寫入 CSV 表頭\n",
    "        writer.writeheader()\n",
    "\n",
    "        for image_key, annotation in annotations.items():\n",
    "            image_filename = annotation[\"filename\"]\n",
    "            image_path = os.path.join(source_folder, image_filename)\n",
    "\n",
    "            regions = annotation[\"regions\"]\n",
    "\n",
    "            # Check conditions for all regions\n",
    "            valid_regions = [region for region in regions if is_valid_region(region)]\n",
    "\n",
    "            # Check if any valid region has a width/height ratio > 1.5\n",
    "            has_valid_region = any(valid_regions) and any(region[\"width_height_ratio\"] > 1.5 for region in valid_regions)\n",
    "\n",
    "            if has_valid_region:\n",
    "                # Create target folder if it doesn't exist\n",
    "                os.makedirs(target_folder, exist_ok=True)\n",
    "\n",
    "                # Copy the image to the target folder\n",
    "                target_path = os.path.join(target_folder, image_filename)\n",
    "                shutil.copy(image_path, target_path)\n",
    "\n",
    "                roi_count = len(valid_regions)\n",
    "\n",
    "                # Write to CSV file with error handling\n",
    "                for region in valid_regions:\n",
    "                    try:\n",
    "                        shape_attributes = region['shape_attributes']\n",
    "                        region_attributes = region['region_attributes']\n",
    "\n",
    "                        category = region_attributes.get('category', '')\n",
    "                        word = region_attributes.get('word', '')\n",
    "\n",
    "                        all_points_x = shape_attributes.get('all_points_x', [])\n",
    "                        all_points_y = shape_attributes.get('all_points_y', [])\n",
    "\n",
    "                        box = list(zip(all_points_x, all_points_y))\n",
    "                        \n",
    "                        if category in ['1', '2', '3', '4', '5', '6']:\n",
    "                            writer.writerow({\n",
    "                                'raw_filename': image_filename,\n",
    "                                'ROI_count': roi_count,\n",
    "                                'category': category,\n",
    "                                'box': box,\n",
    "                                'words': word\n",
    "                            })\n",
    "                    except UnicodeEncodeError as e:\n",
    "                        # Print the error message and continue to the next row\n",
    "                        print(f\"Error writing row for '{image_filename}': {e}\")\n",
    "                        continue\n",
    "\n",
    "def is_valid_region(region):\n",
    "    word = region[\"region_attributes\"].get(\"word\", \"\")\n",
    "    if '*' not in word and any(c.isalpha() for c in word):\n",
    "        x_coordinates = region[\"shape_attributes\"][\"all_points_x\"]\n",
    "        y_coordinates = region[\"shape_attributes\"][\"all_points_y\"]\n",
    "        width = max(x_coordinates) - min(x_coordinates)\n",
    "        height = max(y_coordinates) - min(y_coordinates)\n",
    "\n",
    "        # Calculate width/height ratio\n",
    "        ratio = width / height\n",
    "\n",
    "        # Store width/height ratio in region for later use\n",
    "        region[\"width_height_ratio\"] = ratio\n",
    "\n",
    "        return ratio > 1.5\n",
    "\n",
    "    return False\n",
    "\n",
    "# Replace these paths with your actual paths\n",
    "\n",
    "for field in fields:\n",
    "    annotation_file_path = f\"C:\\\\Users\\\\MAGIC\\\\Ching\\\\survey\\\\plan\\\\rawdata_all\\\\{field}\\\\{field}_ori_all.json\"\n",
    "    source_folder = f\"C:\\\\Users\\\\MAGIC\\\\Ching\\\\survey\\\\plan\\\\rawdata_all\\\\{field}\\\\images\"\n",
    "    target_folder = f\"C:\\\\Users\\\\MAGIC\\\\Ching\\\\survey\\\\plan\\\\rawdata_all\\\\{field}\\\\ocrRaw2\"\n",
    "    os.makedirs(target_folder, exist_ok=True)\n",
    "    csv_file_path = os.path.join(target_folder, 'output2.csv')\n",
    "\n",
    "    copy_images_with_conditions(annotation_file_path, source_folder, target_folder, csv_file_path)\n",
    "    print(f'{field}的圖片和 CSV: {csv_file_path} 已完成')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2422d5ad",
   "metadata": {},
   "source": [
    "### 記得要刪掉重疊的!!!!\n",
    "CSV檔案中存在重複的標記:\n",
    "    filename                            words                   raw_filename  \\\n",
    "148  185.jpg              大臺南會展中心\\nICC Tainan  221005_014356855_Camera_0.jpg   \n",
    "152  185.jpg              大臺南會展中心\\nICC Tainan  221005_014356855_Camera_0.jpg   \n",
    "153  185.jpg              大臺南會展中心\\nICC Tainan  221005_014356855_Camera_0.jpg   \n",
    "250  306.jpg  汽機車停車場\\nCar and Motorcycle Park  221005_014559627_Camera_0.jpg   \n",
    "252  306.jpg  汽機車停車場\\nCar and Motorcycle Park  221005_014559627_Camera_0.jpg   \n",
    "261  319.jpg                 快速公路\\nEXPRESSWAY  221005_014648729_Camera_0.jpg   \n",
    "264  319.jpg                 快速公路\\nEXPRESSWAY  221005_014648729_Camera_0.jpg   \n",
    "265  319.jpg                 快速公路\\nEXPRESSWAY  221005_014648729_Camera_0.jpg   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d3f1d8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "資料夾中的所有圖片都在CSV中找到。\n",
      "\n",
      "CSV檔案中沒有重複的標記。\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "csv_path = \"C:\\\\Users\\\\MAGIC\\\\Ching\\\\survey\\\\plan\\\\rawdata_all\\\\ocrROI\\\\train\\\\1Tainan\\\\labels.csv\"\n",
    "folder_path = \"C:\\\\Users\\\\MAGIC\\\\Ching\\\\survey\\\\plan\\\\rawdata_all\\\\ocrROI\\\\train\\\\1Tainan\"\n",
    "\n",
    "df = pd.read_csv(csv_path, encoding='big5')\n",
    "\n",
    "csv_filenames = set(df['filename'].tolist())\n",
    "folder_filenames = set(os.listdir(folder_path))\n",
    "\n",
    "# 找出CSV中存在但資料夾中不存在的檔案\n",
    "missing_files = csv_filenames - folder_filenames\n",
    "\n",
    "# 找出CSV中重複的標記\n",
    "duplicate_labels = df[df.duplicated(subset=['filename'], keep=False)]\n",
    "\n",
    "if len(missing_files) > 0:\n",
    "    print(\"資料夾中缺少的圖片:\")\n",
    "    for file in missing_files:\n",
    "        print(file)\n",
    "else:\n",
    "    print(\"資料夾中的所有圖片都在CSV中找到。\")\n",
    "\n",
    "if not duplicate_labels.empty:\n",
    "    print(\"\\nCSV檔案中存在重複的標記:\")\n",
    "    print(duplicate_labels)\n",
    "else:\n",
    "    print(\"\\nCSV檔案中沒有重複的標記。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9f71e7",
   "metadata": {},
   "source": [
    "### 南崁.的符號無法decode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b98b6b2",
   "metadata": {},
   "source": [
    "Error writing row for '220707_060614804_Camera_1.jpg': 'big5' codec can't encode character '\\u2027' in position 92: illegal multibyte sequence\n",
    "Error writing row for '220707_060617550_Camera_1.jpg': 'big5' codec can't encode character '\\u2027' in position 92: illegal multibyte sequence\n",
    "Error writing row for '220707_060722774_Camera_1.jpg': 'big5' codec can't encode character '\\u2027' in position 92: illegal multibyte sequence\n",
    "Error writing row for '220707_060801663_Camera_1.jpg': 'big5' codec can't encode character '\\u2027' in position 92: illegal multibyte sequence\n",
    "Error writing row for '220707_060950255_Camera_1.jpg': 'big5' codec can't encode character '\\u2027' in position 92: illegal multibyte sequence\n",
    "Error writing row for '220707_060951671_Camera_1.jpg': 'big5' codec can't encode character '\\u2027' in position 92: illegal multibyte sequence\n",
    "Error writing row for '220707_060952938_Camera_1.jpg': 'big5' codec can't encode character '\\u2027' in position 92: illegal multibyte sequence\n",
    "Error writing row for '220707_030343373_Camera_1.jpg': 'big5' codec can't encode character '\\u2027' in position 92: illegal multibyte sequence\n",
    "Error writing row for '220707_030715653_Camera_1.jpg': 'big5' codec can't encode character '\\u2027' in position 92: illegal multibyte sequence\n",
    "Error writing row for '220707_030716727_Camera_1.jpg': 'big5' codec can't encode character '\\u2027' in position 92: illegal multibyte sequence\n",
    "Error writing row for '220707_030717264_Camera_1.jpg': 'big5' codec can't encode character '\\u2027' in position 92: illegal multibyte sequence\n",
    "Error writing row for '220707_030728389_Camera_1.jpg': 'big5' codec can't encode character '\\u2027' in position 92: illegal multibyte sequence\n",
    "Error writing row for '220707_030728915_Camera_1.jpg': 'big5' codec can't encode character '\\u2027' in position 92: illegal multibyte sequence\n",
    "Error writing row for '220707_030728915_Camera_1.jpg': 'big5' codec can't encode character '\\u2027' in position 92: illegal multibyte sequence\n",
    "Error writing row for '220707_030729441_Camera_1.jpg': 'big5' codec can't encode character '\\u2027' in position 92: illegal multibyte sequence\n",
    "Error writing row for '220707_030729441_Camera_1.jpg': 'big5' codec can't encode character '\\u2027' in position 92: illegal multibyte sequence\n",
    "Error writing row for '220707_032755076_Camera_1.jpg': 'big5' codec can't encode character '\\u2027' in position 92: illegal multibyte sequence\n",
    "Error writing row for '220707_033559873_Camera_1.jpg': 'big5' codec can't encode character '\\u2027' in position 92: illegal multibyte sequence\n",
    "Error writing row for '220707_061120592_Camera_1.jpg': 'big5' codec can't encode character '\\u2027' in position 92: illegal multibyte sequence\n",
    "Error writing row for '220707_061123781_Camera_1.jpg': 'big5' codec can't encode character '\\u2027' in position 92: illegal multibyte sequence\n",
    "Error writing row for '220707_060908688_Camera_1.jpg': 'big5' codec can't encode character '\\u2027' in position 93: illegal multibyte sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166282c6",
   "metadata": {},
   "source": [
    "# 切割出ROI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d40f61e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = ['1Tainan', '2Penghu', '3Taoyuan']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af75b67b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "field='1Tainan'\n",
      "Skipping row: 221005_022119052_Camera_0.jpg invalid literal for int() with base 10: 'B_4'\n",
      "Skipping row: 221005_022119269_Camera_0.jpg invalid literal for int() with base 10: 'B_4'\n",
      "Skipping row: 221005_022119491_Camera_0.jpg invalid literal for int() with base 10: 'B_4'\n",
      "Skipping row: 221005_032452506_Camera_0.jpg invalid literal for int() with base 10: 'B_4'\n",
      "Skipping row: 221005_032453266_Camera_0.jpg invalid literal for int() with base 10: 'B_4'\n",
      "Skipping row: 221005_032453512_Camera_0.jpg invalid literal for int() with base 10: 'B_4'\n",
      "Skipping row: 221005_032626335_Camera_0.jpg invalid literal for int() with base 10: 'B_4'\n",
      "Skipping row: 221005_032626335_Camera_0.jpg invalid literal for int() with base 10: 'B_4'\n",
      "Skipping row: 221005_032626548_Camera_0.jpg invalid literal for int() with base 10: 'B_4'\n",
      "Skipping row: 221005_033320224_Camera_0.jpg invalid literal for int() with base 10: 'B_4'\n",
      "Skipping row: 221005_033404633_Camera_0.jpg invalid literal for int() with base 10: 'B_4'\n",
      "Skipping row: 221005_033404784_Camera_0.jpg invalid literal for int() with base 10: 'B_4'\n",
      "Skipping row: 221005_034701967_Camera_0.jpg invalid literal for int() with base 10: 'B_4'\n",
      "Skipping row: 221005_034702240_Camera_0.jpg invalid literal for int() with base 10: 'B_4'\n",
      "Skipping row: 221005_034702516_Camera_0.jpg invalid literal for int() with base 10: 'B_4'\n",
      "Skipping row: 221005_035604808_Camera_0.jpg invalid literal for int() with base 10: 'B_4'\n",
      "C:\\Users\\MAGIC\\Ching\\survey\\plan\\rawdata_all\\1Tainan\\ocrRaw\\ROI\\ROI.csv 已完成\n",
      "42.34378528594971\n",
      "\n",
      "field='2Penghu'\n",
      "C:\\Users\\MAGIC\\Ching\\survey\\plan\\rawdata_all\\2Penghu\\ocrRaw\\ROI\\ROI.csv 已完成\n",
      "46.91233801841736\n",
      "\n",
      "field='3Taoyuan'\n",
      "Skipping row: 220707_030132932_Camera_1.jpg invalid literal for int() with base 10: 'A_1'\n",
      "C:\\Users\\MAGIC\\Ching\\survey\\plan\\rawdata_all\\3Taoyuan\\ocrRaw\\ROI\\ROI.csv 已完成\n",
      "51.62569975852966\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "from ast import literal_eval\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "def crop_and_save_images(src_csv, src_img, dst_img, new_csv_file, csv_header, field):\n",
    "    with open(src_csv, 'r', encoding='big5') as csv_file:\n",
    "        csv_reader = csv.DictReader(csv_file)\n",
    "        rows = list(csv_reader)\n",
    "    os.makedirs(dst_img, exist_ok=True)\n",
    "\n",
    "    with open(new_csv_file, 'w', encoding='big5', newline='') as csvfile:\n",
    "        csv_writer = csv.writer(csvfile)\n",
    "        csv_writer.writerow(csv_header)\n",
    "\n",
    "        for row in rows:\n",
    "            try:\n",
    "                raw_filename = row['raw_filename']\n",
    "                roi_count = int(row['ROI_count'])\n",
    "                category = int(row['category'])\n",
    "                box = literal_eval(row['box'])\n",
    "                words = row['words'].strip()\n",
    "\n",
    "                if category in [1, 2, 3, 4, 5, 6]:\n",
    "#                     print(raw_filename)\n",
    "#                     print(row)\n",
    "\n",
    "                    image_path = os.path.join(src_img, raw_filename)\n",
    "\n",
    "                    image = Image.open(image_path)\n",
    "                    try:\n",
    "                        exif = image._getexif()\n",
    "                        orientation = exif.get(274, 1)  # 274 是 Exif 中方向信息的標籤\n",
    "                        # print(orientation)\n",
    "                    except (AttributeError, KeyError, IndexError):\n",
    "                        orientation = 1  # 如果沒有 Exif 信息，預設為 1\n",
    "\n",
    "                    # 根據方向信息進行旋轉\n",
    "                    if orientation == 3:\n",
    "                        image = image.rotate(180, expand=True)\n",
    "                    elif orientation == 6:\n",
    "                        image = image.rotate(-90, expand=True)\n",
    "                    elif orientation == 8:\n",
    "                        image = image.rotate(90, expand=True)\n",
    "\n",
    "                    # 根據 box 切割影像\n",
    "                    x1, y1 = min(box, key=lambda x: x[0])[0], min(box, key=lambda x: x[1])[1]\n",
    "                    x2, y2 = max(box, key=lambda x: x[0])[0], max(box, key=lambda x: x[1])[1]\n",
    "\n",
    "                    cropped_image = image.crop((x1, y1, x2, y2))\n",
    "\n",
    "                    new_filename = f'{rows.index(row)}.jpg'\n",
    "                    new_image_path = os.path.join(dst_img, new_filename)\n",
    "                    cropped_image.save(new_image_path)\n",
    "\n",
    "                    csv_writer.writerow([new_filename, words, raw_filename, category])\n",
    "#                     print('-'*80)\n",
    "\n",
    "\n",
    "            except ValueError as e:\n",
    "                print(f\"Skipping row: {row['raw_filename']} {e}\")\n",
    "                continue\n",
    "\n",
    "for field in fields:\n",
    "    src_img = f'C:\\\\Users\\\\MAGIC\\\\Ching\\\\survey\\\\plan\\\\rawdata_all\\\\{field}\\\\ocrRaw'\n",
    "    dst_img = f'C:\\\\Users\\\\MAGIC\\\\Ching\\\\survey\\\\plan\\\\rawdata_all\\\\{field}\\\\ocrRaw\\\\ROI'\n",
    "    src_csv = f'C:\\\\Users\\\\MAGIC\\\\Ching\\\\survey\\\\plan\\\\rawdata_all\\\\{field}\\\\ocrRaw\\\\output.csv'\n",
    "    new_csv_file = os.path.join(dst_img, 'ROI.csv')\n",
    "    csv_header = ['filename', 'words', 'raw_filename', 'category']\n",
    "\n",
    "    print(f'{field=}')\n",
    "    crop_and_save_images(src_csv, src_img, dst_img, new_csv_file, csv_header, field)\n",
    "    print(f'{new_csv_file} 已完成')\n",
    "    print(time.time()-t0)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f2af57",
   "metadata": {},
   "source": [
    "# 依比例切割資料集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8edf0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = ['1Tainan', '2Penghu', '3Taoyuan']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09a8d504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "field='1Tainan'\n",
      "C:\\Users\\MAGIC\\Ching\\survey\\plan\\rawdata_all\\ocrROI\\train\\1Tainan\\labels.csv is done\n",
      "C:\\Users\\MAGIC\\Ching\\survey\\plan\\rawdata_all\\ocrROI\\val\\1Tainan\\labels.csv is done\n",
      "C:\\Users\\MAGIC\\Ching\\survey\\plan\\rawdata_all\\ocrROI\\test\\1Tainan\\labels.csv is done\n",
      "field='2Penghu'\n",
      "C:\\Users\\MAGIC\\Ching\\survey\\plan\\rawdata_all\\ocrROI\\train\\2Penghu\\labels.csv is done\n",
      "C:\\Users\\MAGIC\\Ching\\survey\\plan\\rawdata_all\\ocrROI\\val\\2Penghu\\labels.csv is done\n",
      "C:\\Users\\MAGIC\\Ching\\survey\\plan\\rawdata_all\\ocrROI\\test\\2Penghu\\labels.csv is done\n",
      "field='3Taoyuan'\n",
      "C:\\Users\\MAGIC\\Ching\\survey\\plan\\rawdata_all\\ocrROI\\train\\3Taoyuan\\labels.csv is done\n",
      "C:\\Users\\MAGIC\\Ching\\survey\\plan\\rawdata_all\\ocrROI\\val\\3Taoyuan\\labels.csv is done\n",
      "C:\\Users\\MAGIC\\Ching\\survey\\plan\\rawdata_all\\ocrROI\\test\\3Taoyuan\\labels.csv is done\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "from shutil import copyfile\n",
    "\n",
    "for field in fields:\n",
    "    # 資料夾路徑\n",
    "    data_folder = dst_img = f'C:\\\\Users\\\\MAGIC\\\\Ching\\\\survey\\\\plan\\\\rawdata_all\\\\{field}\\\\ocrRaw\\\\ROI'\n",
    "    output_train_folder = f'C:\\\\Users\\\\MAGIC\\\\Ching\\\\survey\\\\plan\\\\rawdata_all\\\\ocrROI\\\\train\\\\{field}'\n",
    "    output_val_folder = f'C:\\\\Users\\\\MAGIC\\\\Ching\\\\survey\\\\plan\\\\rawdata_all\\\\ocrROI\\\\val\\\\{field}'\n",
    "    output_test_folder = f'C:\\\\Users\\\\MAGIC\\\\Ching\\\\survey\\\\plan\\\\rawdata_all\\\\ocrROI\\\\test\\\\{field}'\n",
    "    labels_file = os.path.join(data_folder, 'ROI.csv')\n",
    "\n",
    "    # 設定訓練集、驗證集和測試集比例 (K:N:M)\n",
    "    K = 8  # 設定為8表示訓練集佔80%，驗證集和測試集各佔10%\n",
    "    N = 1\n",
    "    M = 1\n",
    "\n",
    "    os.makedirs(output_train_folder, exist_ok=True)\n",
    "    os.makedirs(output_val_folder, exist_ok=True)\n",
    "    os.makedirs(output_test_folder, exist_ok=True)\n",
    "\n",
    "    labels_df = pd.read_csv(labels_file, encoding='big5')\n",
    "\n",
    "    # 創建一個字典，用於將標籤映射到相應的檔案\n",
    "    label_to_filenames = {}\n",
    "    for index, row in labels_df.iterrows():\n",
    "        filename = row['filename']\n",
    "        label = row['words']\n",
    "        if label in label_to_filenames:\n",
    "            label_to_filenames[label].append(filename)\n",
    "        else:\n",
    "            label_to_filenames[label] = [filename]\n",
    "\n",
    "    # 分配資料到訓練集、驗證集和測試集\n",
    "    cnt_tr = 0\n",
    "    cnt_va = 0\n",
    "    cnt_test = 0\n",
    "    print(f'{field=}')\n",
    "    for label, filenames in label_to_filenames.items():\n",
    "        num_samples = len(filenames)\n",
    "        if num_samples == 1:\n",
    "            num_test_samples = 0\n",
    "            num_val_samples = 0\n",
    "            num_train_samples = 1\n",
    "\n",
    "        elif num_samples == 2:\n",
    "            num_test_samples = 1\n",
    "            num_val_samples = 0\n",
    "            num_train_samples = 1\n",
    "\n",
    "        elif num_samples < 6:\n",
    "            num_test_samples = 1\n",
    "            num_val_samples = 1\n",
    "            num_train_samples = num_samples -2\n",
    "\n",
    "        else:\n",
    "            num_test_samples = round((num_samples / (K + N + M)) * M)\n",
    "            num_val_samples = round((num_samples / (K + N + M)) * N)\n",
    "            num_train_samples = num_samples - num_test_samples - num_val_samples\n",
    "\n",
    "            random.shuffle(filenames)\n",
    "\n",
    "\n",
    "        test_samples = filenames[:num_test_samples]\n",
    "        val_samples = filenames[num_test_samples:num_test_samples + num_val_samples]\n",
    "        train_samples = filenames[num_test_samples + num_val_samples:]\n",
    "\n",
    "    #     print()\n",
    "    #     print(f'{label=}')\n",
    "    #     print(f'{filenames=}')\n",
    "    #     print(f'{num_samples=}')\n",
    "    #     print(f'{num_train_samples=}')\n",
    "    #     print(f'{num_val_samples=}')\n",
    "    #     print(f'{num_test_samples=}')\n",
    "    #     print('*'*80)\n",
    "\n",
    "        # 複製影像到對應的資料夾\n",
    "        for filename in train_samples:\n",
    "            cnt_tr += 1 \n",
    "            source_image = os.path.join(data_folder, filename)\n",
    "            destination_image = os.path.join(output_train_folder, filename)\n",
    "            copyfile(source_image, destination_image)\n",
    "\n",
    "        for filename in val_samples:\n",
    "            source_image = os.path.join(data_folder, filename)\n",
    "            destination_image = os.path.join(output_val_folder, filename)\n",
    "            copyfile(source_image, destination_image)\n",
    "\n",
    "        for filename in test_samples:\n",
    "            source_image = os.path.join(data_folder, filename)\n",
    "            destination_image = os.path.join(output_test_folder, filename)\n",
    "            copyfile(source_image, destination_image)\n",
    "\n",
    "    # 創建新的標記檔\n",
    "    train_labels = labels_df[labels_df['filename'].isin(os.listdir(output_train_folder))]\n",
    "    val_labels = labels_df[labels_df['filename'].isin(os.listdir(output_val_folder))]\n",
    "    test_labels = labels_df[labels_df['filename'].isin(os.listdir(output_test_folder))]\n",
    "\n",
    "    train_labels.to_csv(os.path.join(output_train_folder, 'labels.csv'), index=False, encoding='big5')\n",
    "    val_labels.to_csv(os.path.join(output_val_folder, 'labels.csv'), index=False, encoding='big5')\n",
    "    test_labels.to_csv(os.path.join(output_test_folder, 'labels.csv'), index=False, encoding='big5')\n",
    "\n",
    "    # print(f'{len(train_samples)=}')\n",
    "    # print(f'{len(val_samples)=}')\n",
    "    # print(f'{len(test_samples)=}')\n",
    "    # total = len(train_samples) + len(val_samples) + len(test_samples)\n",
    "    # print((len(train_samples)/total), (len(val_samples)/total), (len(test_samples)/total))\n",
    "    print(f\"{os.path.join(output_train_folder, 'labels.csv')} is done\")\n",
    "    print(f\"{os.path.join(output_val_folder, 'labels.csv')} is done\")\n",
    "    print(f\"{os.path.join(output_test_folder, 'labels.csv')} is done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bce277a",
   "metadata": {},
   "source": [
    "# 合併不同區域的標記檔"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32a80935",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from shutil import copyfile\n",
    "\n",
    "fields = ['1Tainan', '2Penghu', '3Taoyuan']\n",
    "output_train_folder = r'C:\\Users\\MAGIC\\Ching\\survey\\plan\\rawdata_all\\ocrROI\\train_all'\n",
    "output_val_folder = r'C:\\Users\\MAGIC\\Ching\\survey\\plan\\rawdata_all\\ocrROI\\val_all'\n",
    "output_test_folder = r'C:\\Users\\MAGIC\\Ching\\survey\\plan\\rawdata_all\\ocrROI\\test_all'\n",
    "\n",
    "os.makedirs(output_train_folder, exist_ok=True)\n",
    "os.makedirs(output_val_folder, exist_ok=True)\n",
    "os.makedirs(output_test_folder, exist_ok=True)\n",
    "\n",
    "# 合併各field的資料\n",
    "for field in fields:\n",
    "    field_train_folder = f'C:\\\\Users\\\\MAGIC\\\\Ching\\\\survey\\\\plan\\\\rawdata_all\\\\ocrROI\\\\train\\\\{field}'\n",
    "    field_val_folder = f'C:\\\\Users\\\\MAGIC\\\\Ching\\\\survey\\\\plan\\\\rawdata_all\\\\ocrROI\\\\val\\\\{field}'\n",
    "    field_test_folder = f'C:\\\\Users\\\\MAGIC\\\\Ching\\\\survey\\\\plan\\\\rawdata_all\\\\ocrROI\\\\test\\\\{field}'\n",
    "\n",
    "    # 將field的training dataset複製到統一的training資料夾，避免檔名覆蓋問題\n",
    "    for filename in os.listdir(field_train_folder):\n",
    "        source_image = os.path.join(field_train_folder, filename)\n",
    "        destination_image = os.path.join(output_train_folder, f'{field}_{filename}')\n",
    "        copyfile(source_image, destination_image)\n",
    "\n",
    "    # 將field的validation dataset複製到統一的validation資料夾，避免檔名覆蓋問題\n",
    "    for filename in os.listdir(field_val_folder):\n",
    "        source_image = os.path.join(field_val_folder, filename)\n",
    "        destination_image = os.path.join(output_val_folder, f'{field}_{filename}')\n",
    "        copyfile(source_image, destination_image)\n",
    "\n",
    "    # 將field的test dataset複製到統一的testing資料夾，避免檔名覆蓋問題\n",
    "    for filename in os.listdir(field_test_folder):\n",
    "        source_image = os.path.join(field_test_folder, filename)\n",
    "        destination_image = os.path.join(output_test_folder, f'{field}_{filename}')\n",
    "        copyfile(source_image, destination_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14cd069c",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = ['test_all', 'train_all', 'val_all']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5c53fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 合併標記檔\n",
    "for dataset in datasets:\n",
    "    labels_dfs = []\n",
    "    output_combined_csv = f'C:\\\\Users\\\\MAGIC\\\\Ching\\\\survey\\\\plan\\\\rawdata_all\\\\ocrROI\\\\{dataset}\\\\labels.csv'\n",
    "    for field in fields:\n",
    "        field_labels_file = f'C:\\\\Users\\\\MAGIC\\\\Ching\\\\survey\\\\plan\\\\rawdata_all\\\\ocrROI\\\\{dataset}\\\\{field}_labels.csv'\n",
    "        labels_df = pd.read_csv(field_labels_file, encoding='big5')\n",
    "        labels_df['filename'] = labels_df['filename'].apply(lambda x: f'{field}_{x}')  # 將filename加上field的前綴\n",
    "        labels_dfs.append(labels_df)\n",
    "\n",
    "    # 將標記檔合併\n",
    "    merged_labels_df = pd.concat(labels_dfs, ignore_index=True)\n",
    "    merged_labels_df['filename'] = merged_labels_df['filename'].apply(lambda x: x.replace(',', ' '))\n",
    "    merged_labels_df['words'] = merged_labels_df['words'].apply(lambda x: x.replace(',', ' '))\n",
    "\n",
    "    merged_labels_df.to_csv(output_combined_csv, index=False, encoding='big5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f65f4c",
   "metadata": {},
   "source": [
    "# 確認是否有沒有重疊"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4787d80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== test_all ===\n",
      "資料夾中的所有圖片都在CSV中找到\n",
      "****************************************\n",
      "CSV檔案中沒有重複的標記。\n",
      "--------------------------------------------------------------------------------\n",
      "=== train_all ===\n",
      "資料夾中的所有圖片都在CSV中找到\n",
      "****************************************\n",
      "CSV檔案中沒有重複的標記。\n",
      "--------------------------------------------------------------------------------\n",
      "=== val_all ===\n",
      "資料夾中的所有圖片都在CSV中找到\n",
      "****************************************\n",
      "CSV檔案中沒有重複的標記。\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def compare_labels_and_images(field):\n",
    "    labels_path = f\"C:\\\\Users\\\\MAGIC\\\\Ching\\\\survey\\\\plan\\\\rawdata_all\\\\ocrROI\\\\{field}\\\\labels.csv\"\n",
    "    images_path = f\"C:\\\\Users\\\\MAGIC\\\\Ching\\\\survey\\\\plan\\\\rawdata_all\\\\ocrROI\\\\{field}\"\n",
    "\n",
    "    df = pd.read_csv(labels_path, encoding='big5')\n",
    "\n",
    "    csv_filenames = set(df['filename'].tolist())\n",
    "    folder_filenames = set(os.listdir(images_path))\n",
    "\n",
    "    # 找出CSV中存在但資料夾中不存在的檔案\n",
    "    missing_files = csv_filenames - folder_filenames\n",
    "\n",
    "    # 找出CSV中重複的標記\n",
    "    duplicate_labels = df[df.duplicated(subset=['filename'], keep=False)]\n",
    "\n",
    "    if len(missing_files) > 0:\n",
    "        print(f'=== {dataset} ===')\n",
    "        print(\"資料夾中缺少的圖片:\")\n",
    "        for file in missing_files:\n",
    "            print(file)\n",
    "    else:\n",
    "        print(f'=== {dataset} ===')\n",
    "        print(\"資料夾中的所有圖片都在CSV中找到\")\n",
    "\n",
    "    print('*'*40)\n",
    "    if not duplicate_labels.empty:\n",
    "        print(\"CSV檔案中存在重複的標記:\")\n",
    "        print(duplicate_labels)\n",
    "    else:\n",
    "        print(\"CSV檔案中沒有重複的標記。\")\n",
    "\n",
    "datasets = ['test_all', 'train_all', 'val_all']\n",
    "for dataset in datasets:\n",
    "    compare_labels_and_images(dataset)\n",
    "    print('-'*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b86d5f12",
   "metadata": {},
   "source": [
    "# 將英文字拿掉"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eec65379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已將標記檔字符刪除，並儲存到 C:\\Users\\MAGIC\\Ching\\survey\\plan\\rawdata_all\\ocrROI\\test_all\\labels_cleaned.csv\n",
      "已將標記檔字符刪除，並儲存到 C:\\Users\\MAGIC\\Ching\\survey\\plan\\rawdata_all\\ocrROI\\train_all\\labels_cleaned.csv\n",
      "已將標記檔字符刪除，並儲存到 C:\\Users\\MAGIC\\Ching\\survey\\plan\\rawdata_all\\ocrROI\\val_all\\labels_cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def clean_and_save_labels(labels_path):\n",
    "    labels_df = pd.read_csv(labels_path, encoding='big5')\n",
    "\n",
    "    # 刪除 words 中的英文字母、數字和不希望的字符（包括 . 和 &＆）\n",
    "    labels_df['words'] = labels_df['words'].replace(to_replace=\"[a-zA-Z0-9\\n.&＆]+\", value=\"\", regex=True)\n",
    "\n",
    "    cleaned_labels_path = labels_path.replace(\".csv\", \"_cleaned.csv\")\n",
    "    labels_df.to_csv(cleaned_labels_path, index=False, encoding='big5')\n",
    "\n",
    "    print(f\"已將標記檔字符刪除，並儲存到 {cleaned_labels_path}\")\n",
    "\n",
    "datasets = ['test_all', 'train_all', 'val_all']\n",
    "for dataset in datasets:\n",
    "    labels_path = f\"C:\\\\Users\\\\MAGIC\\\\Ching\\\\survey\\\\plan\\\\rawdata_all\\\\ocrROI\\\\{dataset}\\\\labels.csv\"\n",
    "    clean_and_save_labels(labels_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f365689",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8631cb1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
